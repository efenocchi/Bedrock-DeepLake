{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Lake Rest API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_answer(queries: list, org_id: str, dataset_name: str, k=4, number_of_images=3):\n",
    "    url = f\"https://beta.activeloop.dev/api/query/colpali/{org_id}/{dataset_name}\"\n",
    "\n",
    "    data = {\n",
    "        \"queries\": queries,\n",
    "        \"k\": 4,\n",
    "        \"number_of_images\": 3,\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('TOKEN')}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_images(value_returned: dict):\n",
    "    for idx_question, img_list in enumerate(value_returned[\"images\"]):\n",
    "        for idx_img, img in enumerate(img_list):\n",
    "            image_data = base64.b64decode(img)\n",
    "            image = Image.open(BytesIO(image_data))\n",
    "            image.save(f\"question_{idx_question}_image_{idx_img}.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the best images and get the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def send_request(query: list, org_id: str, dataset_name: str):\n",
    "\n",
    "    value_returned = get_answer(query, org_id, dataset_name)\n",
    "    save_images(value_returned)\n",
    "\n",
    "    for img_list in value_returned[\"images\"]:\n",
    "        for img in img_list:\n",
    "            byte_image = base64.b64decode(img)\n",
    "            answer = get_bedrock_answer_with_images(query, byte_image)\n",
    "            print(\"the answer is: \", answer)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "org_id = \"emanuelebeta\"\n",
    "dataset_name = \"ingestion_ml_test2_colpali\"\n",
    "questions = \"describe the Gaussian distribution curve\"\n",
    "send_request(questions, org_id, dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "def embedding_function(texts, model=\"text-embedding-3-large\"):\n",
    "\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    try:\n",
    "        texts = [t.replace(\"\\n\", \" \") for t in texts]\n",
    "    except:\n",
    "        pass\n",
    "    return [\n",
    "        data.embedding\n",
    "        for data in openai.embeddings.create(input=texts, model=model).data\n",
    "    ]\n",
    "\n",
    "\n",
    "def retrieve_context_from_deeplake(vector_store_db, user_question, deep_memory):\n",
    "    # deep memory inside the vectore store ==> deep_memory=True\n",
    "    answer = vector_store_db.search(\n",
    "        embedding_data=user_question,\n",
    "        embedding_function=embedding_function,\n",
    "        deep_memory=deep_memory,\n",
    "        return_view=False,\n",
    "        k=4,\n",
    "    )\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "question = \"\"\n",
    "legal_dataset = \"hub://activeloop/deep_memory_legal_dataset_24\"\n",
    "vector_store = VectorStore(legal_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the answer with and without Deep Memory using Bedrock and Claude Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "deep_memory_chunks = retrieve_context_from_deeplake(\n",
    "    vector_store, el, deep_memory=True\n",
    ")\n",
    "no_deep_memory_chunks = retrieve_context_from_deeplake(\n",
    "    vector_store, el, deep_memory=False\n",
    ")\n",
    "\n",
    "final_answer_deep_memory = get_bedrock_answer_with_text(el, deep_memory_chunks)\n",
    "final_answer_no_deep_memory = get_bedrock_answer_with_text(\n",
    "    el, no_deep_memory_chunks\n",
    ")\n",
    "print(\n",
    "    f\"final answer deep memory: {final_answer_deep_memory} for question {idx}\"\n",
    ")\n",
    "print(\n",
    "    f\"final answer no deep memory: {final_answer_no_deep_memory} for question {idx}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
